{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "import copy\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 생성(이미지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scalp_Health_Dataset(Dataset) :\n",
    "    def __init__(self, image_path_list, vals_list) : # 용량을 고려해 이미지는 경로만 받는걸로\n",
    "        self.image_path_list = image_path_list\n",
    "        self.vals_list = vals_list\n",
    "    def __len__(self) : \n",
    "        return len(self.image_path_list)\n",
    "\n",
    "    def __getitem__(self, index) : # 한 개의 데이터 가져오는 함수\n",
    "        # 224 X 224로 전처리\n",
    "        to_tensor = transforms.ToTensor()\n",
    "        img = to_tensor(Image.open(self.image_path_list[index]).convert('RGB'))\n",
    "        img.resize_(3, 224, 224)\n",
    "        img = torch.divide(img, 255.0) # 텐서로 변경 후 이미지 리사이징하고 각 채널을 0~1 사이의 값으로 만들어버림\n",
    "        \n",
    "        label = self.vals_list[index]\n",
    "        \n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 생성(두피 상태별 정도)\n",
    "\n",
    "#### 데이터 분석 결과, 하나의 두피 이미지가 여러 증상을 가지고 있는 경우도 있음을 확인했다. \n",
    "#### 그래서 양호 0.2, 비듬 0.5...등으로 데이터를 만들려고 한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터셋의 라벨에 해당하는 val1~val6이 여기서 입력값임\n",
    "class Scalp_classifier_Dataset(Dataset) :\n",
    "    def __init__(self, vals_list, severity_per_class_list) : # state_list : val1~val6 label_list : 증상별 중증도가 기록(예 : [0.33, 0.00, 1.00,...0.66])\n",
    "        self.vals_list = vals_list\n",
    "        self.severity_per_class_list = severity_per_class_list\n",
    "    def __len__(self) : \n",
    "        return len(self.vals_list)\n",
    "\n",
    "    def __getitem__(self, index) : # 한 개의 데이터 가져오는 함수\n",
    "        \n",
    "        state = self.vals_list[index] # val1~val6\n",
    "        label = self.severity_per_class_list[index]\n",
    "        \n",
    "        return state, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(dataset_path, category) : # root_path + '/Train'이나 root_path + '/Label'을 받음\n",
    "    \n",
    "    \n",
    "    image_group_folder_path = dataset_path + '/Image'\n",
    "    label_group_folder_path = dataset_path + '/Label'\n",
    "    \n",
    "    ori_label_folder_list = os.listdir(label_group_folder_path) # '[라벨]피지과다_3.중증' 등 폴더명 알기\n",
    "    \n",
    "    label_folder_list = []\n",
    "    \n",
    "    for i in range(len(ori_label_folder_list)) :\n",
    "        if ori_label_folder_list[i] != '.DS_Store' : # '.DS_Store'가 생성되었을 수 있으니 폴더 목록에서 제외\n",
    "            label_folder_list.append(ori_label_folder_list[i])\n",
    "    \n",
    "    image_path_list = []\n",
    "    vals_list = []\n",
    "    class_str_list = []\n",
    "    \n",
    "    desc_str = category + \"_make_dataset\"\n",
    "    \n",
    "    for i in tqdm(range(len(label_folder_list)), desc = desc_str) :\n",
    "                  \n",
    "        label_folder_path = label_group_folder_path + \"/\" + label_folder_list[i]\n",
    "        \n",
    "        # label_folder_list에서 '라벨'을 '원천'으로 만 바꿔도 image파일들이 들어있는 폴더명으로 만들 수 있다\n",
    "        image_folder_path = image_group_folder_path + \"/\" + label_folder_list[i].replace('라벨', '원천')\n",
    "        \n",
    "        json_list = os.listdir(label_folder_path) # json파일 목록 담기\n",
    "\n",
    "        for j in range(len(json_list)) : \n",
    "            json_file_path = label_folder_path + '/' + json_list[j]\n",
    "\n",
    "            with open(json_file_path, \"r\", encoding=\"utf8\") as f: \n",
    "                contents = f.read() # string 타입 \n",
    "                json_content = json.loads(contents) # 딕셔너리로 저장\n",
    "\n",
    "            image_file_name = json_content['image_file_name'] # 라벨 데이터에 이미지 파일의 이름이 들어있다\n",
    "            \n",
    "            image_file_path = image_folder_path + \"/\" + image_file_name\n",
    "\n",
    "            # val1 ~ val6\n",
    "            vals_true = []\n",
    "            vals_true.append(int(json_content['value_1']))\n",
    "            vals_true.append(int(json_content['value_2']))\n",
    "            vals_true.append(int(json_content['value_3']))\n",
    "            vals_true.append(int(json_content['value_4']))\n",
    "            vals_true.append(int(json_content['value_5']))\n",
    "            vals_true.append(int(json_content['value_6']))\n",
    "\n",
    "            vals_true = torch.Tensor(vals_true).type(torch.float32)\n",
    "\n",
    "            image_path_list.append(image_file_path)\n",
    "            vals_list.append(vals_true/3.0)\n",
    "            class_str_list.append(label_folder_list[i][4:]) # 이미지마다 할당된 클래스를 담음\n",
    "\n",
    "    return image_path_list, vals_list, class_str_list\n",
    "    # image_path_list : 파일 경로가 저장된 리스트\n",
    "    # vals_list : val1 ~ val6이 들어있는 Tensor 리스트\n",
    "    # class_str_list : \"모낭사이홍반_0.양호\" 등의 문자열이 저장된 리스트\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나의 모발 이미지가 여러 증상을 가진 경우가 있다.\n",
    "# 하나의 이미지가 [A증상 중증, B증상 경증] 등 여러 증상에 대한 중증도를 나타내게끔 라벨 데이터를 만들어주는 기능도 한다\n",
    "# 즉, 데이터 전처리\n",
    "def make_unique_dataset(image_path_list, vals_list, class_str_list) :  \n",
    "    unique_image_path_list = []\n",
    "    unique_vals_list = []\n",
    "    unique_severity_per_class_list = []\n",
    "    \n",
    "    state_str_list = [\"미세각질\", \"피지과다\", \"모낭사이홍반\", \"모낭홍반농포\", \"비듬\", \"탈모\", \"양호\"]\n",
    "    \n",
    "    for i in tqdm(range(len(image_path_list)), desc = \"make unique dataset\" ) : \n",
    "        file_name = image_path_list[i].split('/')[-1] # 이미지 파일 이름\n",
    "        \n",
    "        # 모낭사이홍반 등 증상이 적힌 문자열만 추출\n",
    "        if class_str_list[i].find(\"중등도\") != -1 :  \n",
    "            class_str = class_str_list[i][:-6] \n",
    "        else :\n",
    "            class_str = class_str_list[i][:-5]\n",
    "        \n",
    "        # 중증 정도\n",
    "        severity_num = float(re.sub(r'[^0-9]', '', class_str_list[i]))\n",
    "        severity = torch.Tensor([severity_num]).type(torch.float32)/3.0\n",
    "        \n",
    "        # 증상을 one-hot encoding형식으로 처리(1이 들어갈 자리에 1대신 중증도를 나타낸 숫자를 넣음)\n",
    "        # 주의 : '양호'한 모발의 severity_per_class는 [0,0,0,0,0,0,1]이다\n",
    "        if torch.eq(severity, 0.0) == True :\n",
    "            class_str_index = state_str_list.index(\"양호\")\n",
    "        else : \n",
    "            class_str_index = state_str_list.index(class_str)\n",
    "        \n",
    "        severity_per_class = torch.zeros(len(state_str_list)).type(torch.float32)\n",
    "        severity_per_class[class_str_index] = severity\n",
    "        \n",
    "        # 만들고 있던 unique list의 안에 같은 파일이름을 가진게 없는지 확인\n",
    "        is_sameFilename_here = False\n",
    "        for j in range(len(unique_image_path_list)) :\n",
    "            if unique_image_path_list[j].split('/')[-1] == file_name : # 중복된 파일이 있으면\n",
    "                # 클래스별 중증도만 통합\n",
    "                unique_severity_per_class_list[j] = unique_severity_per_class_list[j] + severity_per_class\n",
    "                is_sameFilename_here = True\n",
    "                \n",
    "        if is_sameFilename_here == False :\n",
    "            unique_image_path_list.append(image_path_list[i])\n",
    "            unique_vals_list.append(vals_list[i])\n",
    "            unique_severity_per_class_list.append(severity_per_class)\n",
    "    \n",
    "    return unique_image_path_list, unique_vals_list, unique_severity_per_class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(root_path) : \n",
    "    \n",
    "    Train_image_path_list, Train_vals_list, Train_class_str_list = make_dataset(root_path + '/Train', \"Train\")\n",
    "    Train_image_path_list, Train_vals_list, Train_severity_per_class_list = make_unique_dataset(Train_image_path_list, Train_vals_list, Train_class_str_list)\n",
    "    \n",
    "    \n",
    "    Test_image_path_list, Test_vals_list, Test_class_str_list = make_dataset(root_path + '/Test', \"Test\")\n",
    "    Test_image_path_list, Test_vals_list, Test_severity_per_class_list = make_unique_dataset(Test_image_path_list, Test_vals_list, Test_class_str_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Train_Scalp_Health_Dataset = Scalp_Health_Dataset(Train_image_path_list, Train_vals_list)\n",
    "    Test_Scalp_Health_Dataset = Scalp_Health_Dataset(Test_image_path_list, Test_vals_list)\n",
    "    \n",
    "    Train_Scalp_classifier_Dataset = Scalp_classifier_Dataset(Train_vals_list, Train_severity_per_class_list)\n",
    "    Test_Scalp_classifier_Dataset = Scalp_classifier_Dataset(Test_vals_list, Test_severity_per_class_list)\n",
    "    \n",
    "    return Train_Scalp_Health_Dataset, Test_Scalp_Health_Dataset, Train_Scalp_classifier_Dataset, Test_Scalp_classifier_Dataset\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습시키는 메소드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, epochs, data_loader, device, desc_str) :\n",
    "    # 학습 -> 성능 측정\n",
    "    \n",
    "    pred_loss = -1.0\n",
    "    checkpoint_model = 0\n",
    "    \n",
    "    pbar = tqdm(range(epochs), desc = desc_str, mininterval=0.01)\n",
    "    \n",
    "\n",
    "    for epoch in pbar:  # loop over the dataset multiple times\n",
    "            \n",
    "        if desc_str == \"training CNN\" and (epoch == int(epochs * 0.5) or epoch == int(epochs * 0.75)) : # 31, 61번 째 에포크에서 학습률을 10배 줄임\n",
    "            optimizer.param_groups[0]['lr'] = optimizer.param_groups[0]['lr'] / 10.0\n",
    "            \n",
    "        for inputs, labels in data_loader:\n",
    "            \n",
    "            # get the inputs\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "                \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            pbar_str = \"training CNN\" + \", [loss = %.4f]\" % loss.item()\n",
    "            pbar.set_description(pbar_str)\n",
    "            \n",
    "            # 체크포인트\n",
    "            # 배치 단위로 학습시킬 때마다 체크포인트 저장 여부 확인\n",
    "            if pred_loss == -1.0 :\n",
    "                pred_loss = loss\n",
    "                checkpoint_model = copy.deepcopy(model)\n",
    "            elif torch.lt(loss, pred_loss) == True : # loss를 더 줄였으면\n",
    "                pred_loss = loss\n",
    "                checkpoint_model = copy.deepcopy(model)\n",
    "    \n",
    "    # 체크포인트에 저장했던걸 최종 모델로\n",
    "    model = copy.deepcopy(checkpoint_model)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train_make_dataset: 100%|██████████| 24/24 [00:00<00:00, 53.65it/s]\n",
      "make unique dataset: 100%|██████████| 7968/7968 [00:15<00:00, 502.70it/s] \n",
      "Test_make_dataset: 100%|██████████| 24/24 [00:00<00:00, 185.64it/s]\n",
      "make unique dataset: 100%|██████████| 2280/2280 [00:01<00:00, 1556.09it/s]\n"
     ]
    }
   ],
   "source": [
    "root_path = '/home/ubuntu/CUAI_2021/Advanced_Minkyu_Kim/Scalp_Health_Dataset'\n",
    "# root_path = '/Users/minkyukim/Downloads/Scalp_Health_Dataset'\n",
    "Train_Scalp_Health_Dataset, Test_Scalp_Health_Dataset, Train_Scalp_classifier_Dataset, Test_Scalp_classifier_Dataset = get_dataset(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 사용\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "data_loader_Scalp_Health_Dataset = torch.utils.data.DataLoader(dataset=Train_Scalp_Health_Dataset, # 사용할 데이터셋\n",
    "                                          batch_size=BATCH_SIZE, # 미니배치 크기\n",
    "                                          shuffle=True, # 에포크마다 데이터셋 셔플할건가? \n",
    "                                          drop_last=True) # 마지막 배치가 BATCH_SIZE보다 작을 수 있다. 나머지가 항상 0일 수는 없지 않는가. 이 때 마지막 배치는 사용하지 않으려면 drop_last = True를, 사용할거면 drop_last = False를 입력한다\n",
    "\n",
    "data_loader_Scalp_classifier_Dataset = torch.utils.data.DataLoader(dataset=Train_Scalp_classifier_Dataset, # 사용할 데이터셋\n",
    "                                          batch_size=BATCH_SIZE, # 미니배치 크기\n",
    "                                          shuffle=True, # 에포크마다 데이터셋 셔플할건가? \n",
    "                                          drop_last=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디바이스 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# 에포크 설정\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN 생성 : DenseNet_161에 classifier만 수정해서 학습시킨다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CNN = models.densenet161(pretrained = True, memory_efficient = True).to(device)\n",
    "\n",
    "# ImageNet으로 학습시킨 CNN은 수정하지 못하게끔\n",
    "for param in model_CNN.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_CNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9d7cba4a29da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel_CNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_classifier\u001b[0m \u001b[0;31m# 교체\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_CNN' is not defined"
     ]
    }
   ],
   "source": [
    "# 모발 분류를 위한 linear model 생성 후 교체\n",
    "new_classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=2208, out_features=6, bias=True)\n",
    "            , nn.Sigmoid() # 0~1사이 값으로 만들어버림\n",
    "        ).to(device)\n",
    "\n",
    "for m in new_classifier.modules():\n",
    "    if isinstance(m, nn.Linear) :\n",
    "        nn.init.kaiming_uniform_(m.weight)\n",
    "        \n",
    "model_CNN.classifier = new_classifier # 교체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 학습에 필요한 것들\n",
    "optimizer_CNN = torch.optim.SGD(model_CNN.parameters(), lr=0.1, momentum = 0.9, weight_decay = 1e-4)\n",
    "loss_CNN = nn.MSELoss() # 5종류의 출력값을 예측하는 선형회귀 모델이라 MSE사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training, [loss = 0.0782]: 100%|██████████| 300/300 [19:39:14<00:00, 235.85s/it]  \n"
     ]
    }
   ],
   "source": [
    "model_CNN = train_model(model_CNN, loss_CNN, optimizer_CNN, EPOCHS, data_loader_Scalp_Health_Dataset, device, \"training CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_CNN(torch.unsqueeze(Train_Scalp_Health_Dataset[0][0], 0).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### val1~val6을 입력값으로 받아 증상별 중증도를 출력하는 네트워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Diagnoser = nn.Sequential(\n",
    "            nn.Linear(in_features=6, out_features=64, bias=True),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=64, out_features=128, bias=True),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=128, out_features=256, bias=True),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=256, out_features=128, bias=True),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=128, out_features=64, bias=True), \n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=64, out_features=32, bias=True), \n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=32, out_features=7, bias=False), \n",
    "            nn.Sigmoid()\n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss_diagnoser = nn.MSELoss()\n",
    "optimizer_diagnoser = torch.optim.Adam(scalp_state_diagnoser.parameters(), lr=0.001, weight_decay = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training CNN, [loss = 0.0178]: 100%|██████████| 100/100 [00:10<00:00,  9.67it/s]\n"
     ]
    }
   ],
   "source": [
    "model_Diagnoser = train_model(model_Diagnoser, loss_diagnoser, optimizer_diagnoser, EPOCHS, data_loader_Scalp_classifier_Dataset, device, \"training Diagnoser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습한 모델 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/ubuntu/CUAI_2021/Advanced_Minkyu_Kim/Scalp_model_parameters/'\n",
    "\n",
    "torch.save(model_CNN.state_dict(), PATH + 'model_CNN_parameter.pt')\n",
    "torch.save(model_Diagnoser.state_dict(), PATH + 'model_Diagnoser_parameter.pt')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aac1938eb6913997aabd086dca6066ca74adbc6b4a9aafd1e6821241d3ac0498"
  },
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
