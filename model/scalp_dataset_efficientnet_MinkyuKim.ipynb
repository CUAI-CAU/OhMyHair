{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "import copy\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 생성(이미지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scalp_Health_Dataset(Dataset) :\n",
    "    def __init__(self, image_path_list, label_list) : # 용량을 고려해 이미지는 경로만 받는걸로\n",
    "        self.image_path_list = image_path_list\n",
    "        self.label_list = label_list\n",
    "    def __len__(self) : \n",
    "        return len(self.image_path_list)\n",
    "\n",
    "    def __getitem__(self, index) : # 한 개의 데이터 가져오는 함수\n",
    "        # 224 X 224로 전처리\n",
    "        \n",
    "        to_tensor = transforms.ToTensor()\n",
    "        img = to_tensor(Image.open(self.image_path_list[index]).convert('RGB'))\n",
    "        img.resize_(3, 224, 224)\n",
    "        img = torch.divide(img, 255.0) # 텐서로 변경 후 이미지 리사이징하고 각 채널을 0~1 사이의 값으로 만들어버림\n",
    "        \n",
    "        label = torch.tensor(self.label_list[index])\n",
    "        \n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 생성(두피 상태, 중증도 분별)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터셋의 라벨에 해당하는 val1~val6이 여기서 입력값임\n",
    "class Scalp_classifier_Dataset(Dataset) :\n",
    "    def __init__(self, state_list, label_list) : # state_list : val1~val6 label_list : \"모낭사이홍반_0.양호\" 등의 문자열\n",
    "        self.state_list = state_list\n",
    "        self.label_list = label_list\n",
    "        self.state_str_list = [\"미세각질\", \"피지과다\", \"모낭사이홍반\", \"모낭홍반농포\", \"비듬\", \"탈모\", \"양호\"]\n",
    "    def __len__(self) : \n",
    "        return len(self.state_list)\n",
    "\n",
    "    def __getitem__(self, index) : # 한 개의 데이터 가져오는 함수\n",
    "        \n",
    "        state = torch.Tensor(self.state_list[index])\n",
    "        label_str = self.label_list[index]\n",
    "        \n",
    "        # \"모낭사이홍반_0.양호\" 문자열이 들어있는 label_list를 분리\n",
    "        if self.label_list[index].find(\"중등도\") != -1 :  \n",
    "            class_str = label_str[:-6] # 모낭사이홍반 등 증상\n",
    "        else :\n",
    "            class_str = label_str[:-5]\n",
    "        \n",
    "        \n",
    "        severity_num = float(re.sub(r'[^0-9]', '', label_str))\n",
    "        severity = torch.Tensor([severity_num]).type(torch.float32)/3.0\n",
    "        \n",
    "        # one-hot encoding\n",
    "        if torch.eq(severity, 0.0) == True :\n",
    "            class_str_index = self.state_str_list.index(\"양호\")\n",
    "            label_one_hot = torch.zeros(len(self.state_str_list)).type(torch.LongTensor)\n",
    "            label_one_hot[class_str_index] = 1\n",
    "        else : \n",
    "            class_str_index = self.state_str_list.index(class_str)\n",
    "            label_one_hot = torch.zeros(len(self.state_str_list)).type(torch.LongTensor)\n",
    "            label_one_hot[class_str_index] = 1\n",
    "        \n",
    "        label = [label_one_hot, severity]\n",
    "        \n",
    "        \n",
    "        return state, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(dataset_path, category) : # root_path + '/Train'이나 root_path + '/Label'을 받음\n",
    "    \n",
    "    \n",
    "    image_group_folder_path = dataset_path + '/Image'\n",
    "    label_group_folder_path = dataset_path + '/Label'\n",
    "    \n",
    "    ori_label_folder_list = os.listdir(label_group_folder_path) # '[라벨]피지과다_3.중증' 등 폴더명 알기\n",
    "    \n",
    "    label_folder_list = []\n",
    "    \n",
    "    for i in range(len(ori_label_folder_list)) :\n",
    "        if ori_label_folder_list[i] != '.DS_Store' : # '.DS_Store'가 생성되었을 수 있으니 폴더 목록에서 제외\n",
    "            label_folder_list.append(ori_label_folder_list[i])\n",
    "    \n",
    "    image_path_list = []\n",
    "    label_list = []\n",
    "    label_class_list = []\n",
    "    \n",
    "    desc_str = category + \"_make_dataset\"\n",
    "    \n",
    "    for i in tqdm(range(len(label_folder_list)), desc = desc_str) :\n",
    "                  \n",
    "        label_folder_path = label_group_folder_path + \"/\" + label_folder_list[i]\n",
    "        \n",
    "        # label_folder_list에서 '라벨'을 '원천'으로 만 바꿔도 image파일들이 들어있는 폴더명으로 만들 수 있다\n",
    "        image_folder_path = image_group_folder_path + \"/\" + label_folder_list[i].replace('라벨', '원천')\n",
    "        \n",
    "        json_list = os.listdir(label_folder_path) # json파일 목록 담기\n",
    "\n",
    "        for j in range(len(json_list)) : \n",
    "            json_file_path = label_folder_path + '/' + json_list[j]\n",
    "\n",
    "            with open(json_file_path, \"r\", encoding=\"utf8\") as f: \n",
    "                contents = f.read() # string 타입 \n",
    "                json_content = json.loads(contents) # 딕셔너리로 저장\n",
    "\n",
    "            image_file_name = json_content['image_file_name'] # 라벨 데이터에 이미지 파일의 이름이 들어있다\n",
    "            \n",
    "            image_file_path = image_folder_path + \"/\" + image_file_name\n",
    "\n",
    "            y_true = []\n",
    "            y_true.append(int(json_content['value_1']))\n",
    "            y_true.append(int(json_content['value_2']))\n",
    "            y_true.append(int(json_content['value_3']))\n",
    "            y_true.append(int(json_content['value_4']))\n",
    "            y_true.append(int(json_content['value_5']))\n",
    "            y_true.append(int(json_content['value_6']))\n",
    "\n",
    "            y_true = np.asarray(y_true)\n",
    "\n",
    "            image_path_list.append(image_file_path)\n",
    "            label_list.append(y_true/3.0) # val1~val6의 범위가 0,1,2,3이라 3으로 나눠줌\n",
    "            label_class_list.append(label_folder_list[i][4:]) # 이미지마다 할당된 클래스를 담음\n",
    "\n",
    "    return image_path_list, label_list, label_class_list\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(root_path) : \n",
    "    \n",
    "    Train_image_path_list, Train_label_list, Train_label_class_list = make_dataset(root_path + '/Train', \"Train\")\n",
    "    Test_image_path_list, Test_label_list, Test_label_class_list = make_dataset(root_path + '/Test', \"Test\")\n",
    "    \n",
    "    Train_Scalp_Health_Dataset = Scalp_Health_Dataset(Train_image_path_list, Train_label_list)\n",
    "    Test_Scalp_Health_Dataset = Scalp_Health_Dataset(Test_image_path_list, Test_label_list)\n",
    "    \n",
    "    \n",
    "    Train_Scalp_classifier_Dataset = Scalp_classifier_Dataset(Train_label_list, Train_label_class_list)\n",
    "    Test_Scalp_classifier_Dataset = Scalp_classifier_Dataset(Test_label_list, Test_label_class_list)\n",
    "    \n",
    "    return Train_Scalp_Health_Dataset, Test_Scalp_Health_Dataset, Train_Scalp_classifier_Dataset, Test_Scalp_classifier_Dataset\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습시키는 메소드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, epochs, data_loader, device, desc_str) :\n",
    "    # 학습 -> 성능 측정\n",
    "    \n",
    "    pred_loss = -1.0\n",
    "    checkpoint_model = 0\n",
    "    \n",
    "    pbar = tqdm(range(epochs), desc = desc_str, mininterval=0.01)\n",
    "    \n",
    "\n",
    "    for epoch in pbar:  # loop over the dataset multiple times\n",
    "            \n",
    "        if epoch == int(epochs * 0.5) or int(epochs * 0.75) : # 31, 61번 째 에포크에서 학습률을 10배 줄임\n",
    "            optimizer.param_groups[0]['lr'] = optimizer.param_groups[0]['lr'] / 10.0\n",
    "            \n",
    "        \n",
    "        for inputs, labels in data_loader:\n",
    "            \n",
    "            # get the inputs\n",
    "            inputs = inputs.to(device)\n",
    "            \n",
    "            # label data로 텐서가 왔는지 리스트가 왔는지 확인\n",
    "            if type(labels) == type([]) :\n",
    "                labels[0] = labels[0].to(device)\n",
    "                labels[1] = labels[1].to(device)\n",
    "            else : \n",
    "                labels = labels.to(device)\n",
    "                \n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            pbar_str = \"training, [loss = %.4f]\" % loss.item()\n",
    "            pbar.set_description(pbar_str)\n",
    "            \n",
    "            # 체크포인트\n",
    "            # 배치 단위로 학습시킬 때마다 체크포인트 저장 여부 확인\n",
    "            if pred_loss == -1.0 :\n",
    "                pred_loss = loss\n",
    "                checkpoint_model = copy.deepcopy(model)\n",
    "            elif torch.lt(loss, pred_loss) == True : # loss를 더 줄였으면\n",
    "                pred_loss = loss\n",
    "                checkpoint_model = copy.deepcopy(model)\n",
    "    \n",
    "    # 체크포인트에 저장했던걸 최종 모델로\n",
    "    model = checkpoint_model\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train_make_dataset: 100%|██████████| 24/24 [00:01<00:00, 16.12it/s]\n",
      "Test_make_dataset: 100%|██████████| 24/24 [00:00<00:00, 113.00it/s]\n"
     ]
    }
   ],
   "source": [
    "root_path = '/home/ubuntu/CUAI_2021/Advanced_Minkyu_Kim/Scalp_Health_Dataset'\n",
    "# root_path = '/Users/minkyukim/Downloads/Scalp_Health_Dataset'\n",
    "Train_Scalp_Health_Dataset, Test_Scalp_Health_Dataset, Train_Scalp_classifier_Dataset, Test_Scalp_classifier_Dataset = get_dataset(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 사용\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "data_loader_Scalp_Health_Dataset = torch.utils.data.DataLoader(dataset=Train_Scalp_Health_Dataset, # 사용할 데이터셋\n",
    "                                          batch_size=BATCH_SIZE, # 미니배치 크기\n",
    "                                          shuffle=True, # 에포크마다 데이터셋 셔플할건가? \n",
    "                                          drop_last=True) # 마지막 배치가 BATCH_SIZE보다 작을 수 있다. 나머지가 항상 0일 수는 없지 않는가. 이 때 마지막 배치는 사용하지 않으려면 drop_last = True를, 사용할거면 drop_last = False를 입력한다\n",
    "\n",
    "data_loader_Scalp_classifier_Dataset = torch.utils.data.DataLoader(dataset=Train_Scalp_classifier_Dataset, # 사용할 데이터셋\n",
    "                                          batch_size=BATCH_SIZE, # 미니배치 크기\n",
    "                                          shuffle=True, # 에포크마다 데이터셋 셔플할건가? \n",
    "                                          drop_last=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 네트워크 생성 : DenseNet_161에 classifier만 수정해서 학습시킨다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디바이스 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model_CNN = models.densenet161(pretrained = True, memory_efficient = True).to(device)\n",
    "\n",
    "# ImageNet으로 학습시킨 CNN은 수정하지 못하게끔\n",
    "for param in model_CNN.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모발 분류를 위한 linear model 생성 후 교체\n",
    "new_classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=2208, out_features=6, bias=True)\n",
    "            , nn.Sigmoid() # 0~1사이 값으로 만들어버림\n",
    "        ).to(device)\n",
    "\n",
    "for m in new_classifier.modules():\n",
    "    if isinstance(m, nn.Linear) :\n",
    "        nn.init.kaiming_uniform_(m.weight)\n",
    "        \n",
    "model_CNN.classifier = new_classifier # 교체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_CNN(torch.unsqueeze(Train_Scalp_Health_Dataset[0][0], 0).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지에서 얻은 val1~val6을 입력값으로 받아 (증상 종류), (중증도)를 출력하는 네트워크 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scalp_state_diagnoser(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(scalp_state_diagnoser, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(in_features=6, out_features=16, bias=True),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=16, out_features=8, bias=True)\n",
    "        )\n",
    "        # 모발 상태 판단\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=8, out_features=7, bias=True), # [미세각질, 피지과다, 모낭사이홍반, 모낭홍반농포, 비듬, 탈모, 양호]\n",
    "            nn.Softmax(dim = 0)\n",
    "        )\n",
    "        # 중증도 판단\n",
    "        self.severity = nn.Sequential(\n",
    "            nn.Linear(in_features=8, out_features=1, bias=True), # 0, 0.33, 0.66, 1.0\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        for m in self.classifier.modules():\n",
    "            if isinstance(m, nn.Linear) :\n",
    "                nn.init.kaiming_uniform_(m.weight)\n",
    "                \n",
    "        for m in self.severity.modules():\n",
    "            if isinstance(m, nn.Linear) :\n",
    "                nn.init.kaiming_uniform_(m.weight)\n",
    "                \n",
    "    # 정전파 \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        \n",
    "        classifier_out = self.classifier(out)\n",
    "        severity_out = self.severity(out)\n",
    "        \n",
    "        return [classifier_out, severity_out]\n",
    "    \n",
    "def loss_Diagnoser(y_pred, y_true) :\n",
    "    # y는 [상태, 중증도]의 리스트로 구성 \n",
    "    class_pred = y_pred[0]\n",
    "    severity_pred = y_pred[1]\n",
    "    \n",
    "    class_true = y_true[0]\n",
    "    severity_true = y_true[1]\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    class_loss = loss(class_pred, class_true)\n",
    "    severity_loss = loss(severity_pred, severity_true)\n",
    "    \n",
    "    total_loss = torch.add(class_loss, severity_loss)\n",
    "    \n",
    "    return total_loss\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 학습에 필요한 것들\n",
    "\n",
    "optimizer_CNN = torch.optim.SGD(model_CNN.parameters(), lr=0.1, momentum = 0.9, weight_decay = 1e-4)\n",
    "EPOCHS = 300\n",
    "loss_CNN = nn.MSELoss() # 5종류의 출력값을 예측하는 선형회귀 모델이라 MSE사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnoser 모델과 모델 학습에 필요한 것들\n",
    "\n",
    "model_Diagnoser = scalp_state_diagnoser().to(device)\n",
    "optimizer_Diagnoser = torch.optim.SGD(model_Diagnoser.parameters(), lr=0.001, momentum = 0.9, weight_decay = 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training, [loss = 0.0782]: 100%|██████████| 300/300 [19:39:14<00:00, 235.85s/it]  \n"
     ]
    }
   ],
   "source": [
    "model_CNN = train_model(model_CNN, loss_CNN, optimizer_CNN, EPOCHS, data_loader_Scalp_Health_Dataset, device, \"training CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training Diagnoser:   0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "model_Diagnoser = train_model(model_Diagnoser, loss_Diagnoser, optimizer_Diagnoser, EPOCHS, data_loader_Scalp_classifier_Dataset, device, \"training Diagnoser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습한 모델 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(PATH) : # PATH = '/home/ubuntu/CUAI_2021/Advanced_Minkyu_Kim/Scalp_model_parameters/'\n",
    "    torch.save(model_CNN.state_dict(), PATH + 'model_CNN_parameter.pt')\n",
    "    torch.save(model_Diagnoser.state_dict(), PATH + 'model_Diagnoser_parameter.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_trained(PATH) :\n",
    "    model_CNN = models.densenet161(pretrained = True, memory_efficient = True).to(device)\n",
    "\n",
    "    new_classifier = nn.Sequential(\n",
    "                nn.Linear(in_features=2208, out_features=6, bias=True)\n",
    "                ).to(device)\n",
    "\n",
    "    for m in new_classifier.modules():\n",
    "        if isinstance(m, nn.Linear) :\n",
    "            nn.init.kaiming_uniform_(m.weight)\n",
    "\n",
    "    model_CNN.classifier = new_classifier.to(device) # 교체\n",
    "    \n",
    "    model_Diagnoser = scalp_state_diagnoser().to(device)\n",
    "    \n",
    "    # 학습된 가중치들 불러오기\n",
    "    PATH_model_CNN = PATH + 'model_CNN_parameter.pt'\n",
    "    PATH_model_Diagnoser = PATH + 'model_Diagnoser_parameter.pt'\n",
    "    \n",
    "    model_CNN.load_state_dict(torch.load(PATH_model_CNN))\n",
    "    model_Diagnoser.load_state_dict(torch.load(PATH_model_Diagnoser))\n",
    "    \n",
    "    return model_CNN, model_Diagnoser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value(input_data, model_CNN, model_Diagnoser, device) :\n",
    "    \n",
    "    state_str_list = [\"미세각질\", \"피지과다\", \"모낭사이홍반\", \"모낭홍반농포\", \"비듬\", \"탈모\", \"양호\"]\n",
    "    \n",
    "    input_data = torch.unsqueeze(input_data, 0).to(device)\n",
    "    \n",
    "    output = model_CNN(input_data)\n",
    "    output = model_Diagnoser(output)\n",
    "    \n",
    "    scalp_state_idx = torch.argmax(output[0])\n",
    "    scalp_state = state_str_list[state_idx] # 두피 상태. state_str_list에 있는 문자열 중 하나가 나옴\n",
    "    severity = torch.round(output[1] * 3).type(torch.int32) # 중증도. 0,1,2,3중 하나가 나옴\n",
    "    \n",
    "    return scalp_state, severity\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aac1938eb6913997aabd086dca6066ca74adbc6b4a9aafd1e6821241d3ac0498"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
