{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scalp_Health_Dataset(Dataset) :\n",
    "    def __init__(self, image_path_list, label_list) : # 용량을 고려해 이미지는 경로만 받는걸로\n",
    "        self.image_path_list = image_path_list\n",
    "        self.label_list = label_list\n",
    "    def __len__(self) : \n",
    "        return len(self.image_path_list)\n",
    "\n",
    "    def __getitem__(self, index) : # 한 개의 데이터 가져오는 함수\n",
    "        # 224 X 224로 전처리\n",
    "        \n",
    "        to_tensor = transforms.ToTensor()\n",
    "        img = to_tensor(Image.open(self.image_path_list[index]).convert('RGB'))\n",
    "        img.resize_(3, 224, 224)\n",
    "        img = torch.divide(img, 255.0) # 텐서로 변경 후 이미지 리사이징하고 각 채널을 0~1 사이의 값으로 만들어버림\n",
    "        \n",
    "        # 출력값은 각 항목(Value1~Value6)은 3으로 나눈 뒤 출력. (각 항목의 최대값이 3)\n",
    "        # 모델에서 출력값을 얻고 3씩 곱해주면 된다\n",
    "        \n",
    "        label = torch.tensor(self.label_list[index]/3.0)\n",
    "        \n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(dataset_path, category) : # root_path + '/Train'이나 root_path + '/Label'을 받음\n",
    "    \n",
    "    \n",
    "    image_group_folder_path = dataset_path + '/Image'\n",
    "    label_group_folder_path = dataset_path + '/Label'\n",
    "    \n",
    "    ori_label_folder_list = os.listdir(label_group_folder_path) # '[라벨]피지과다_3.중증' 등 폴더명 알기\n",
    "    \n",
    "    label_folder_list = []\n",
    "    \n",
    "    for i in range(len(ori_label_folder_list)) :\n",
    "        if ori_label_folder_list[i] != '.DS_Store' : # '.DS_Store'가 생성되었을 수 있으니 폴더 목록에서 제외\n",
    "            label_folder_list.append(ori_label_folder_list[i])\n",
    "    \n",
    "    image_path_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    desc_str = category + \"_make_dataset\"\n",
    "    \n",
    "    for i in tqdm(range(len(label_folder_list)), desc = desc_str) :\n",
    "                  \n",
    "        label_folder_path = label_group_folder_path + \"/\" + label_folder_list[i]\n",
    "        \n",
    "        # label_folder_list에서 '라벨'을 '원천'으로 만 바꿔도 image파일들이 들어있는 폴더명으로 만들 수 있다\n",
    "        image_folder_path = image_group_folder_path + \"/\" + label_folder_list[i].replace('라벨', '원천')\n",
    "        \n",
    "        json_list = os.listdir(label_folder_path) # json파일 목록 담기\n",
    "\n",
    "        for j in range(len(json_list)) : \n",
    "            json_file_path = label_folder_path + '/' + json_list[j]\n",
    "\n",
    "            with open(json_file_path, \"r\", encoding=\"utf8\") as f: \n",
    "                contents = f.read() # string 타입 \n",
    "                json_content = json.loads(contents) # 딕셔너리로 저장\n",
    "\n",
    "            image_file_name = json_content['image_file_name'] # 라벨 데이터에 이미지 파일의 이름이 들어있다\n",
    "            \n",
    "            image_file_path = image_folder_path + \"/\" + image_file_name\n",
    "\n",
    "            y_true = []\n",
    "            y_true.append(int(json_content['value_1']))\n",
    "            y_true.append(int(json_content['value_2']))\n",
    "            y_true.append(int(json_content['value_3']))\n",
    "            y_true.append(int(json_content['value_4']))\n",
    "            y_true.append(int(json_content['value_5']))\n",
    "            y_true.append(int(json_content['value_6']))\n",
    "\n",
    "            y_true = np.asarray(y_true)\n",
    "\n",
    "            image_path_list.append(image_file_path)\n",
    "            label_list.append(y_true)\n",
    "\n",
    "    return image_path_list, label_list\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(root_path) : \n",
    "    \n",
    "    Train_image_path_list, Train_label_list = make_dataset(root_path + '/Train', \"Train\")\n",
    "    Test_image_path_list, Test_label_list = make_dataset(root_path + '/Test', \"Test\")\n",
    "    \n",
    "    Train_Scalp_Health_Dataset = Scalp_Health_Dataset(Train_image_path_list, Train_label_list)\n",
    "    Test_Scalp_Health_Dataset = Scalp_Health_Dataset(Test_image_path_list, Test_label_list)\n",
    "    \n",
    "    return Train_Scalp_Health_Dataset, Test_Scalp_Health_Dataset\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습시키는 메소드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, epochs, data_loader, device) :\n",
    "    # 학습 -> 성능 측정\n",
    "    \n",
    "    pred_loss = -1.0\n",
    "    checkpoint_model = 0\n",
    "    \n",
    "    pbar = tqdm(range(epochs), desc=\"training\", mininterval=0.01)\n",
    "    \n",
    "\n",
    "    for epoch in pbar:  # loop over the dataset multiple times\n",
    "            \n",
    "        if epoch == int(epochs * 0.5) or int(epochs * 0.75) : # 31, 61번 째 에포크에서 학습률을 10배 줄임\n",
    "            optimizer.param_groups[0]['lr'] = optimizer.param_groups[0]['lr'] / 10.0\n",
    "            \n",
    "        \n",
    "        for inputs, labels in data_loader:\n",
    "\n",
    "            # get the inputs\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            pbar_str = \"training, [loss = %.4f]\" % loss.item()\n",
    "            pbar.set_description(pbar_str)\n",
    "            \n",
    "            # 체크포인트\n",
    "            # 배치 단위로 학습시킬 때마다 체크포인트 저장 여부 확인\n",
    "            if pred_loss == -1.0 :\n",
    "                pred_loss = loss\n",
    "                checkpoint_model = copy.deepcopy(model)\n",
    "            elif torch.lt(loss, pred_loss) == True : # loss를 더 줄였으면\n",
    "                pred_loss = loss\n",
    "                checkpoint_model = copy.deepcopy(model)\n",
    "    \n",
    "    # 체크포인트에 저장했던걸 최종 모델로\n",
    "    model = checkpoint_model\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train_make_dataset: 100%|██████████| 24/24 [00:00<00:00, 67.32it/s]\n",
      "Test_make_dataset: 100%|██████████| 24/24 [00:00<00:00, 289.84it/s]\n"
     ]
    }
   ],
   "source": [
    "root_path = '/home/ubuntu/CUAI_2021/Advanced_Minkyu_Kim/Scalp_Health_Dataset'\n",
    "Train_Scalp_Health_Dataset, Test_Scalp_Health_Dataset = get_dataset(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 사용\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset=Train_Scalp_Health_Dataset, # 사용할 데이터셋\n",
    "                                          batch_size=BATCH_SIZE, # 미니배치 크기\n",
    "                                          shuffle=True, # 에포크마다 데이터셋 셔플할건가? \n",
    "                                          drop_last=True) # 마지막 배치가 BATCH_SIZE보다 작을 수 있다. 나머지가 항상 0일 수는 없지 않는가. 이 때 마지막 배치는 사용하지 않으려면 drop_last = True를, 사용할거면 drop_last = False를 입력한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 네트워크 생성 : DenseNet_161에 classifier만 수정해서 학습시킨다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디바이스 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = models.densenet161(pretrained = True, memory_efficient = True).to(device)\n",
    "\n",
    "# ImageNet으로 학습시킨 CNN은 수정하지 못하게끔\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모발 분류를 위한 linear model 생성 후 교체\n",
    "new_classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=2208, out_features=6, bias=True)\n",
    "        ).to(device)\n",
    "\n",
    "for m in new_classifier.modules():\n",
    "    if isinstance(m, nn.Linear) :\n",
    "        nn.init.kaiming_uniform_(m.weight)\n",
    "        \n",
    "model.classifier = new_classifier # 교체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 필요한 것들\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum = 0.9, weight_decay = 1e-4)\n",
    "EPOCHS = 300\n",
    "loss = nn.MSELoss() # 5종류의 출력값을 예측하는 선형회귀 모델이라 MSE사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training, [loss = 0.1450]:   0%|          | 0/300 [01:42<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "model = train_model(model, loss, optimizer, EPOCHS, data_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aac1938eb6913997aabd086dca6066ca74adbc6b4a9aafd1e6821241d3ac0498"
  },
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
